# premiere partie 
### ELK
# ELK Stack Setup (Windows)

## Pr√©requis
- Docker Desktop
- Git Bash

## Installation

### 1. Configurer le fichier .env
Cr√©ez un fichier `.env` avec :
```
ELASTIC_PASSWORD=votremotdepasse
KIBANA_SERVICE_ACCOUNT_TOKEN=
```

### 2. D√©marrer Elasticsearch
```bash
docker-compose up -d elasticsearch
```

### 3. G√©n√©rer le token Kibana
Ouvrir **Git Bash** et ex√©cuter :
```bash
./setup-kibana-token.sh
```

Copier le token g√©n√©r√© et le coller dans `.env`

### 4. D√©marrer Kibana et Logstash
```bash
docker-compose up -d
```

### 5. Acc√©der aux services
- Elasticsearch: http://localhost:9200
- Kibana: http://localhost:5601
- Logstash: localhost:5000

## Red√©marrage
Pour les red√©marrages suivants (token d√©j√† configur√©) :
```bash
docker-compose down
docker-compose up -d

# üìö Guide ELK Stack - Configuration et Test

## üìã Table des mati√®res
1. [Architecture](#architecture)
2. [Pr√©requis](#pr√©requis)
3. [Installation](#installation)
4. [Configuration](#configuration)
5. [Test du pipeline](#test-du-pipeline)
6. [Visualisation dans Kibana](#visualisation-dans-kibana)
7. [Int√©gration Spring Boot](#int√©gration-spring-boot)

---

## üèóÔ∏è Architecture

```
Spring Boot Application
    ‚Üì (TCP:5000 - JSON)
Logstash (Input)
    ‚Üì (Traitement)
Elasticsearch (Stockage)
    ‚Üì (Lecture)
Kibana (Visualisation)
```

---

## ‚úÖ Pr√©requis

- Docker et Docker Compose install√©s
- Port 5000, 5601 et 9200 disponibles

---

## üì¶ Installation

### 1. Structure des fichiers

```
projet/
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .env
‚îî‚îÄ‚îÄ logstash/
    ‚îî‚îÄ‚îÄ pipeline/
        ‚îî‚îÄ‚îÄ logstash.conf
```

## üöÄ Configuration

### 1. D√©marrer la stack ELK

```bash
docker-compose up -d
```

### 2. V√©rifier que les services sont d√©marr√©s

```bash
docker-compose ps
```

**R√©sultat attendu :**
```
NAME            STATUS
elasticsearch   Up (healthy)
logstash        Up
kibana          Up
```

### 3. V√©rifier les logs de Logstash

```bash
docker logs logstash --tail 20
```

**Vous devez voir :**
```
[INFO] Pipelines running {:count=>1, :running_pipelines=>[:main]}
```

**Pas d'erreur 401 !**

---

## üß™ Test du pipeline

### 1. Envoyer un log de test manuel

```bash
docker run --rm alpine sh -c 'echo "{\"message\":\"Test manuel\",\"level\":\"INFO\"}" | nc host.docker.internal 5000'
```

### 2. V√©rifier que l'index a √©t√© cr√©√©

```bash
curl -u elastic:Elastic123! "http://localhost:9200/_cat/indices?v"
```

**Vous devez voir :**
```
yellow open   springboot-logs-2026.02.04   1   6.2kb
```

### 3. V√©rifier le contenu du log

```bash
curl -u elastic:Elastic123! "http://localhost:9200/springboot-logs-*/_search?pretty"
```

**Vous devez voir :**
```json
{
  "_source" : {
    "message" : "Test manuel",
    "level" : "INFO",
    "@timestamp" : "2026-02-04T..."
  }
}
```

---

## üìä Visualisation dans Kibana

### 1. Ouvrir Kibana

```
http://localhost:5601
```

### 2. Cr√©er un Data View

1. Menu (‚ò∞) ‚Üí **Management** ‚Üí **Stack Management**
2. **Kibana** ‚Üí **Data Views**
3. Cliquer sur **Create data view**
4. Remplir :
   - **Name** : `springboot-logs`
   - **Index pattern** : `springboot-logs-*`
   - **Timestamp field** : `@timestamp`
5. Cliquer sur **Save data view to Kibana**

### 3. Voir les logs dans Discover

1. Menu (‚ò∞) ‚Üí **Analytics** ‚Üí **Discover**
2. S√©lectionner `springboot-logs` dans le dropdown (en haut √† gauche)
3. Ajuster la plage de temps en haut √† droite : **Last 24 hours**
4. **Vous voyez vos logs !** üéâ

### 4. Ajouter des colonnes utiles

Dans Discover, cliquer sur **+** √† c√¥t√© de ces champs :
- `level`
- `message`
- `logger_name`

---

## üçÉ Int√©gration Spring Boot

### 1. Ajouter la d√©pendance dans `pom.xml`

```xml
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>7.4</version>
</dependency>
```

### 2. Cr√©er `src/main/resources/logback-spring.xml`

```xml
<configuration>
    <appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <destination>localhost:5000</destination>
        <encoder class="net.logstash.logback.encoder.LogstashEncoder" />
    </appender>
    
    <root level="INFO">
        <appender-ref ref="LOGSTASH" />
    </root>
</configuration>
```

### 3. Cr√©er un contr√¥leur de test

```java
package com.example.demo.controller;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class TestController {
    
    private static final Logger logger = LoggerFactory.getLogger(TestController.class);
    
    @GetMapping("/test")
    public String test() {
        logger.info("Test log envoy√© vers Logstash");
        logger.error("Test erreur");
        return "Logs envoy√©s !";
    }
}
```

### 4. Tester l'application

```bash
# D√©marrer Spring Boot
./mvnw spring-boot:run

# Appeler l'endpoint
curl http://localhost:8080/test

# V√©rifier dans Elasticsearch
curl -u elastic:Elastic123! "http://localhost:9200/springboot-logs-*/_search?pretty&size=2"

# Voir dans Kibana Discover
# Les logs apparaissent automatiquement !
```

---

## üîç Recherches utiles dans Kibana

Dans la barre de recherche KQL :

```
# Logs d'erreur
level: "ERROR"

# Messages contenant "test"
message: *test*

# Erreurs OU warnings
level: ("ERROR" OR "WARN")

# Logs des 15 derni√®res minutes
@timestamp >= now-15m

# Combinaison
level: "ERROR" AND @timestamp >= now-1h
```

---

## üõ†Ô∏è Commandes utiles

### Red√©marrer un service

```bash
docker-compose restart logstash
```

### Voir les logs d'un service

```bash
docker logs -f logstash
docker logs -f elasticsearch
docker logs -f kibana
```

### Arr√™ter la stack

```bash
docker-compose down
```

### Supprimer les donn√©es (volumes)

```bash
docker-compose down -v
```

### Compter les logs

```bash
curl -u elastic:Elastic123! "http://localhost:9200/springboot-logs-*/_count?pretty"
```

### Supprimer un index

```bash
curl -X DELETE -u elastic:Elastic123! "http://localhost:9200/springboot-logs-2026.02.04"
```

---

## üìà Explication du flux

1. **Spring Boot** envoie les logs en JSON via TCP sur le port 5000
2. **Logstash** re√ßoit les logs sur le port 5000
3. **Logstash** ajoute `@timestamp` et `@version`
4. **Logstash** envoie vers Elasticsearch dans l'index `springboot-logs-YYYY.MM.dd`
5. **Elasticsearch** stocke les logs (un nouvel index par jour)
6. **Kibana** lit depuis Elasticsearch et affiche les logs

---

## ‚úÖ Points importants

- ‚úÖ Un **nouvel index est cr√©√© chaque jour** : `springboot-logs-2026.02.04`, `springboot-logs-2026.02.05`, etc.
- ‚úÖ Le statut **yellow** est normal en d√©veloppement (un seul n≈ìud Elasticsearch)
- ‚úÖ Les logs sont **visibles en temps r√©el** dans Kibana
- ‚úÖ La plage de temps par d√©faut dans Kibana est **15 minutes**, pensez √† l'√©largir

---

## üéØ R√©sum√© rapide

```bash
# 1. D√©marrer
docker-compose up -d

# 2. Tester
docker run --rm alpine sh -c 'echo "{\"message\":\"Test\",\"level\":\"INFO\"}" | nc host.docker.internal 5000'

# 3. V√©rifier
curl -u elastic:Elastic123! "http://localhost:9200/springboot-logs-*/_count?pretty"

# 4. Visualiser
# Ouvrir http://localhost:5601
```

---

**Votre stack ELK est op√©rationnelle ! üéâ**


## **Synchronisation manuelle elasticsearch et postgresql !**
Document Technique ‚Äì Configuration Spring Boot avec Elasticsearch et JPA
1Ô∏è‚É£ Contexte

Dans ce projet, nous avons besoin d‚Äôune application Spring Boot qui :

G√®re les utilisateurs dans une base SQL via JPA (UsersEntity).

Indexe les utilisateurs dans Elasticsearch pour permettre des recherches rapides et full-text (UsersDocument).

Assure la synchronisation SQL ‚Üî Elasticsearch √† la cr√©ation, mise √† jour et suppression des utilisateurs.

2Ô∏è‚É£ Structure des Entities / Documents
a) UsersEntity ‚Äì Table SQL
id = Integer auto-incr√©ment√© par la base SQL.

Utilis√© pour toutes les op√©rations CRUD avec JPA.

b) UsersDocument ‚Äì Elasticsearch
id = String ‚Üí correspond √† UsersEntity.id converti en String pour Elasticsearch.
Permet d‚Äô√©viter les erreurs de conversion String -> Integer.

3Ô∏è‚É£ Repositories

Fournit toutes les m√©thodes CRUD SQL.

Permet de rechercher un utilisateur par username ou email.

b) Elasticsearch Repository ‚Äì UserSearchRepository

Fournit toutes les m√©thodes CRUD sur Elasticsearch.

Les recherches sont bas√©es sur les conventions Spring Data.

Type d‚Äôid = String pour √©viter les erreurs de conversion.

4Ô∏è‚É£ Service ‚Äì Gestion des utilisateurs
Assure la synchronisation JPA ‚Üî Elasticsearch √† la cr√©ation et √† la suppression.
Recherche rapide via Elasticsearch.

5Ô∏è‚É£ Configuration Spring Boot
a) application.properties
# Elasticsearch
spring.elasticsearch.uris=http://localhost:9200
spring.elasticsearch.username=elastic
spring.elasticsearch.password=Elastic123!

6Ô∏è‚É£ Kibana ‚Äì V√©rification des donn√©es
Supprimer un document :

DELETE users/_doc/{id}  // id = SQL id converti en String

7Ô∏è‚É£ Bonnes pratiques

Toujours utiliser le m√™me id pour SQL et Elasticsearch pour √©viter les conversions.

Ne pas m√©langer types Integer / String dans les repositories.

Toujours supprimer dans SQL puis dans ES pour rester synchronis√©.

Utiliser findByUsernameContaining pour des recherches partielles.
mais il existe d'autre synchronisation
SolutionComplexit√©Temps r√©elRecommandation
Spring Boot (manuel)‚≠ê Simple‚úÖ OuiD√©butant
Logstash JDBC‚≠ê‚≠ê Moyen‚ùå Non (d√©lai)Bon compromis
Debezium CDC‚≠ê‚≠ê‚≠ê Complexe‚úÖ OuiProduction
Triggers PostgreSQL‚≠ê‚≠ê‚≠ê Complexe‚úÖ OuiRarement